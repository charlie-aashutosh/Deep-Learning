{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating_ANN_from_scratch_using_Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMPziVry+2X6pd3G3UTodX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlie-aashutosh/Deep-Learning/blob/master/Creating_ANN_from_scratch_using_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITU2NDp2CJM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 1 - Data Preprocessing\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7y-6VIFEz3Q",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b9eab4be-dae5-4d80-821c-1e820603e2f8"
      },
      "source": [
        "# Importing the dataset\n",
        "from google.colab import files\n",
        "files=files.upload()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-528c1de4-bff5-4918-88f6-eaefd2708b4e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-528c1de4-bff5-4918-88f6-eaefd2708b4e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb6vTnZgFC8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Churn_Modelling.csv')\n",
        "X = df.iloc[:, 3:13]\n",
        "y = df.iloc[:, 13]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFiIm6WxFODx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "675a07b9-076a-47d1-cb28-bfe3d25b0a49"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NnFbDTxFTRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "81c2473f-ca51-440f-ae76-00352f431431"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0          619    France  Female  ...          1               1        101348.88\n",
              "1          608     Spain  Female  ...          0               1        112542.58\n",
              "2          502    France  Female  ...          1               0        113931.57\n",
              "3          699    France  Female  ...          0               0         93826.63\n",
              "4          850     Spain  Female  ...          1               1         79084.10\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNooO-2sFVkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "75b0fa25-acfc-4ef7-9b33-dc4c6706dae6"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    0\n",
              "4    0\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPXlbPY4FW7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting the categorical data - by using dummy variables\n",
        "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
        "gender=pd.get_dummies(X['Gender'],drop_first=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBWjg-nbFwQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "9a2f768d-7543-41d4-db16-85d96c9e9a4b"
      },
      "source": [
        "geography.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Germany  Spain\n",
              "0        0      0\n",
              "1        0      1\n",
              "2        0      0\n",
              "3        0      0\n",
              "4        0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FgYGk9yF1s9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "1f7e2ae2-4d59-4847-decd-a067a9e4b654"
      },
      "source": [
        "gender.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Male\n",
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1JyUXhjF3W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatinating these into X dataset\n",
        "X=pd.concat([X,geography,gender],axis=1)\n",
        "\n",
        "## Drop Unnecessary columns - since we converted them to dummy variables\n",
        "X=X.drop(['Geography','Gender'],axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKyKqgHGJM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-E5bZyeH5JC",
        "colab_type": "text"
      },
      "source": [
        "Feature Scaling - at times x1, x2, x3 and so on have different magnitude and so while computing wi.xi+bi - it would take time so we try to scale all the given imput features to one scale - we will be able to reach the globl minima easily and wt. updation will be also easy while performing backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf6AfetvGP6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling -\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ7_ksunITk8",
        "colab_type": "text"
      },
      "source": [
        "1.Sequential - used for creating NN\n",
        "2.Dense - the hidden layers we want in our NN\n",
        "3.LeakyReLU and others are the activation funtions used\n",
        "4.Dropout - used for Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDw57xsbGgrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08ea6710-3626-49b9-bcfd-37d0bdf6a99b"
      },
      "source": [
        "# Now let's make the ANN!\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1rrFvNhGl4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialising the ANN - empty NN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhOnIAfhI7N8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "53752bd2-db99-4116-af38-37034de901da"
      },
      "source": [
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu',input_dim = 11))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"he_uniform\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjn0Q1HkJOxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units= 6, kernel_initializer= 'he_uniform',activation='relu',input_dim = 11))\n",
        "classifier.add(Dropout(0.3))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jukww8cJBIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units= 6, kernel_initializer= 'he_uniform',activation='relu'))\n",
        "classifier.add(Dropout(0.4))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units= 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid'))\n",
        "classifier.add(Dropout(0.2))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ3r0yU5KVQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "af34a3c5-b62c-44b8-fba9-e6b74c6657b9"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 7         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 6)                 12        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 7         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 205\n",
            "Trainable params: 205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk5PAem8JwEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59eae2c7-1914-498f-c6db-eb09fcab9fa6"
      },
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, nb_epoch = 100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 5359 samples, validate on 2641 samples\n",
            "Epoch 1/100\n",
            "5359/5359 [==============================] - 2s 345us/step - loss: 1.1211 - accuracy: 0.6397 - val_loss: 0.4712 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "5359/5359 [==============================] - 1s 268us/step - loss: 1.0708 - accuracy: 0.7608 - val_loss: 0.4566 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "5359/5359 [==============================] - 1s 230us/step - loss: 1.0261 - accuracy: 0.7916 - val_loss: 0.4450 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9748 - accuracy: 0.7960 - val_loss: 0.4250 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "5359/5359 [==============================] - 1s 211us/step - loss: 0.9346 - accuracy: 0.7962 - val_loss: 0.4134 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9837 - accuracy: 0.7962 - val_loss: 0.4133 - val_accuracy: 0.7955\n",
            "Epoch 7/100\n",
            "5359/5359 [==============================] - 1s 204us/step - loss: 0.9428 - accuracy: 0.7962 - val_loss: 0.4079 - val_accuracy: 0.7955\n",
            "Epoch 8/100\n",
            "5359/5359 [==============================] - 1s 212us/step - loss: 0.9487 - accuracy: 0.7962 - val_loss: 0.4101 - val_accuracy: 0.7955\n",
            "Epoch 9/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9130 - accuracy: 0.7962 - val_loss: 0.4079 - val_accuracy: 0.7955\n",
            "Epoch 10/100\n",
            "5359/5359 [==============================] - 1s 221us/step - loss: 0.9068 - accuracy: 0.7962 - val_loss: 0.4152 - val_accuracy: 0.7955\n",
            "Epoch 11/100\n",
            "5359/5359 [==============================] - 1s 222us/step - loss: 0.9533 - accuracy: 0.7962 - val_loss: 0.4056 - val_accuracy: 0.7955\n",
            "Epoch 12/100\n",
            "5359/5359 [==============================] - 1s 204us/step - loss: 0.9606 - accuracy: 0.7962 - val_loss: 0.4128 - val_accuracy: 0.7955\n",
            "Epoch 13/100\n",
            "5359/5359 [==============================] - 1s 215us/step - loss: 0.9435 - accuracy: 0.7962 - val_loss: 0.4072 - val_accuracy: 0.7955\n",
            "Epoch 14/100\n",
            "5359/5359 [==============================] - 1s 206us/step - loss: 0.9949 - accuracy: 0.7962 - val_loss: 0.4071 - val_accuracy: 0.7955\n",
            "Epoch 15/100\n",
            "5359/5359 [==============================] - 1s 221us/step - loss: 0.9544 - accuracy: 0.7962 - val_loss: 0.4117 - val_accuracy: 0.7955\n",
            "Epoch 16/100\n",
            "5359/5359 [==============================] - 1s 244us/step - loss: 1.0046 - accuracy: 0.7962 - val_loss: 0.4078 - val_accuracy: 0.7955\n",
            "Epoch 17/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9544 - accuracy: 0.7962 - val_loss: 0.4019 - val_accuracy: 0.7955\n",
            "Epoch 18/100\n",
            "5359/5359 [==============================] - 1s 207us/step - loss: 0.9348 - accuracy: 0.7962 - val_loss: 0.4094 - val_accuracy: 0.7955\n",
            "Epoch 19/100\n",
            "5359/5359 [==============================] - 1s 201us/step - loss: 0.9510 - accuracy: 0.7962 - val_loss: 0.4090 - val_accuracy: 0.7955\n",
            "Epoch 20/100\n",
            "5359/5359 [==============================] - 1s 201us/step - loss: 0.9586 - accuracy: 0.7962 - val_loss: 0.4151 - val_accuracy: 0.7955\n",
            "Epoch 21/100\n",
            "5359/5359 [==============================] - 1s 210us/step - loss: 0.9635 - accuracy: 0.7962 - val_loss: 0.4106 - val_accuracy: 0.7955\n",
            "Epoch 22/100\n",
            "5359/5359 [==============================] - 1s 208us/step - loss: 0.9285 - accuracy: 0.7962 - val_loss: 0.4018 - val_accuracy: 0.7955\n",
            "Epoch 23/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9096 - accuracy: 0.7962 - val_loss: 0.4087 - val_accuracy: 0.7955\n",
            "Epoch 24/100\n",
            "5359/5359 [==============================] - 1s 201us/step - loss: 0.9134 - accuracy: 0.7962 - val_loss: 0.4007 - val_accuracy: 0.7955\n",
            "Epoch 25/100\n",
            "5359/5359 [==============================] - 1s 199us/step - loss: 0.9837 - accuracy: 0.7962 - val_loss: 0.4027 - val_accuracy: 0.7955\n",
            "Epoch 26/100\n",
            "5359/5359 [==============================] - 1s 199us/step - loss: 0.9974 - accuracy: 0.7962 - val_loss: 0.4033 - val_accuracy: 0.7955\n",
            "Epoch 27/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9180 - accuracy: 0.7962 - val_loss: 0.4015 - val_accuracy: 0.7955\n",
            "Epoch 28/100\n",
            "5359/5359 [==============================] - 1s 206us/step - loss: 1.0046 - accuracy: 0.7962 - val_loss: 0.4064 - val_accuracy: 0.7955\n",
            "Epoch 29/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 1.0097 - accuracy: 0.7962 - val_loss: 0.4033 - val_accuracy: 0.7955\n",
            "Epoch 30/100\n",
            "5359/5359 [==============================] - 1s 212us/step - loss: 0.9661 - accuracy: 0.7962 - val_loss: 0.4055 - val_accuracy: 0.7955\n",
            "Epoch 31/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9535 - accuracy: 0.7962 - val_loss: 0.4027 - val_accuracy: 0.7955\n",
            "Epoch 32/100\n",
            "5359/5359 [==============================] - 1s 206us/step - loss: 1.0105 - accuracy: 0.7962 - val_loss: 0.4033 - val_accuracy: 0.7955\n",
            "Epoch 33/100\n",
            "5359/5359 [==============================] - 1s 217us/step - loss: 1.0177 - accuracy: 0.7962 - val_loss: 0.4090 - val_accuracy: 0.7955\n",
            "Epoch 34/100\n",
            "5359/5359 [==============================] - 1s 244us/step - loss: 0.9717 - accuracy: 0.7962 - val_loss: 0.4029 - val_accuracy: 0.7955\n",
            "Epoch 35/100\n",
            "5359/5359 [==============================] - 1s 210us/step - loss: 1.0085 - accuracy: 0.7962 - val_loss: 0.4074 - val_accuracy: 0.7955\n",
            "Epoch 36/100\n",
            "5359/5359 [==============================] - 1s 236us/step - loss: 0.9631 - accuracy: 0.7962 - val_loss: 0.4042 - val_accuracy: 0.7955\n",
            "Epoch 37/100\n",
            "5359/5359 [==============================] - 1s 212us/step - loss: 0.8872 - accuracy: 0.7962 - val_loss: 0.4028 - val_accuracy: 0.7955\n",
            "Epoch 38/100\n",
            "5359/5359 [==============================] - 1s 227us/step - loss: 0.9254 - accuracy: 0.7962 - val_loss: 0.4075 - val_accuracy: 0.7955\n",
            "Epoch 39/100\n",
            "5359/5359 [==============================] - 1s 241us/step - loss: 0.9771 - accuracy: 0.7962 - val_loss: 0.4192 - val_accuracy: 0.7955\n",
            "Epoch 40/100\n",
            "5359/5359 [==============================] - 1s 238us/step - loss: 0.9338 - accuracy: 0.7962 - val_loss: 0.4003 - val_accuracy: 0.7955\n",
            "Epoch 41/100\n",
            "5359/5359 [==============================] - 1s 229us/step - loss: 0.9541 - accuracy: 0.7962 - val_loss: 0.4019 - val_accuracy: 0.7955\n",
            "Epoch 42/100\n",
            "5359/5359 [==============================] - 1s 212us/step - loss: 0.9269 - accuracy: 0.7962 - val_loss: 0.4044 - val_accuracy: 0.7955\n",
            "Epoch 43/100\n",
            "5359/5359 [==============================] - 1s 212us/step - loss: 0.9494 - accuracy: 0.7962 - val_loss: 0.4045 - val_accuracy: 0.7955\n",
            "Epoch 44/100\n",
            "5359/5359 [==============================] - 1s 204us/step - loss: 0.9230 - accuracy: 0.7962 - val_loss: 0.4031 - val_accuracy: 0.7955\n",
            "Epoch 45/100\n",
            "5359/5359 [==============================] - 1s 207us/step - loss: 0.9796 - accuracy: 0.7962 - val_loss: 0.4066 - val_accuracy: 0.7955\n",
            "Epoch 46/100\n",
            "5359/5359 [==============================] - 1s 219us/step - loss: 1.0167 - accuracy: 0.7962 - val_loss: 0.4094 - val_accuracy: 0.7955\n",
            "Epoch 47/100\n",
            "5359/5359 [==============================] - 1s 204us/step - loss: 0.9887 - accuracy: 0.7962 - val_loss: 0.4009 - val_accuracy: 0.7955\n",
            "Epoch 48/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9309 - accuracy: 0.7962 - val_loss: 0.4054 - val_accuracy: 0.7955\n",
            "Epoch 49/100\n",
            "5359/5359 [==============================] - 1s 230us/step - loss: 1.0004 - accuracy: 0.7962 - val_loss: 0.4091 - val_accuracy: 0.7955\n",
            "Epoch 50/100\n",
            "5359/5359 [==============================] - 1s 211us/step - loss: 0.9379 - accuracy: 0.7962 - val_loss: 0.4017 - val_accuracy: 0.7955\n",
            "Epoch 51/100\n",
            "5359/5359 [==============================] - 1s 230us/step - loss: 0.9194 - accuracy: 0.7962 - val_loss: 0.4023 - val_accuracy: 0.7955\n",
            "Epoch 52/100\n",
            "5359/5359 [==============================] - 1s 199us/step - loss: 0.9433 - accuracy: 0.7962 - val_loss: 0.4067 - val_accuracy: 0.7955\n",
            "Epoch 53/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9107 - accuracy: 0.7962 - val_loss: 0.4026 - val_accuracy: 0.7955\n",
            "Epoch 54/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9448 - accuracy: 0.7962 - val_loss: 0.4024 - val_accuracy: 0.7955\n",
            "Epoch 55/100\n",
            "5359/5359 [==============================] - 1s 242us/step - loss: 0.9797 - accuracy: 0.7962 - val_loss: 0.4060 - val_accuracy: 0.7955\n",
            "Epoch 56/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9607 - accuracy: 0.7962 - val_loss: 0.4052 - val_accuracy: 0.7955\n",
            "Epoch 57/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9521 - accuracy: 0.7962 - val_loss: 0.4077 - val_accuracy: 0.7955\n",
            "Epoch 58/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9403 - accuracy: 0.7962 - val_loss: 0.4020 - val_accuracy: 0.7955\n",
            "Epoch 59/100\n",
            "5359/5359 [==============================] - 1s 199us/step - loss: 0.9332 - accuracy: 0.7962 - val_loss: 0.4070 - val_accuracy: 0.7955\n",
            "Epoch 60/100\n",
            "5359/5359 [==============================] - 1s 210us/step - loss: 0.9104 - accuracy: 0.7962 - val_loss: 0.3994 - val_accuracy: 0.7955\n",
            "Epoch 61/100\n",
            "5359/5359 [==============================] - 1s 201us/step - loss: 0.9631 - accuracy: 0.7962 - val_loss: 0.4072 - val_accuracy: 0.7955\n",
            "Epoch 62/100\n",
            "5359/5359 [==============================] - 1s 237us/step - loss: 0.9678 - accuracy: 0.7962 - val_loss: 0.4085 - val_accuracy: 0.7955\n",
            "Epoch 63/100\n",
            "5359/5359 [==============================] - 1s 205us/step - loss: 0.9890 - accuracy: 0.7962 - val_loss: 0.4012 - val_accuracy: 0.7955\n",
            "Epoch 64/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9688 - accuracy: 0.7962 - val_loss: 0.4000 - val_accuracy: 0.7955\n",
            "Epoch 65/100\n",
            "5359/5359 [==============================] - 1s 208us/step - loss: 0.9438 - accuracy: 0.7962 - val_loss: 0.4087 - val_accuracy: 0.7955\n",
            "Epoch 66/100\n",
            "5359/5359 [==============================] - 1s 205us/step - loss: 0.9629 - accuracy: 0.7962 - val_loss: 0.4008 - val_accuracy: 0.7955\n",
            "Epoch 67/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9112 - accuracy: 0.7962 - val_loss: 0.3990 - val_accuracy: 0.7955\n",
            "Epoch 68/100\n",
            "5359/5359 [==============================] - 1s 205us/step - loss: 0.9398 - accuracy: 0.7962 - val_loss: 0.4100 - val_accuracy: 0.7955\n",
            "Epoch 69/100\n",
            "5359/5359 [==============================] - 1s 207us/step - loss: 0.9861 - accuracy: 0.7962 - val_loss: 0.4004 - val_accuracy: 0.7955\n",
            "Epoch 70/100\n",
            "5359/5359 [==============================] - 1s 207us/step - loss: 0.9325 - accuracy: 0.7962 - val_loss: 0.4005 - val_accuracy: 0.7955\n",
            "Epoch 71/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 1.0099 - accuracy: 0.7962 - val_loss: 0.4014 - val_accuracy: 0.7955\n",
            "Epoch 72/100\n",
            "5359/5359 [==============================] - 1s 232us/step - loss: 0.8871 - accuracy: 0.7962 - val_loss: 0.4035 - val_accuracy: 0.7955\n",
            "Epoch 73/100\n",
            "5359/5359 [==============================] - 1s 220us/step - loss: 0.9525 - accuracy: 0.7962 - val_loss: 0.4087 - val_accuracy: 0.7955\n",
            "Epoch 74/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9366 - accuracy: 0.7962 - val_loss: 0.3998 - val_accuracy: 0.7955\n",
            "Epoch 75/100\n",
            "5359/5359 [==============================] - 1s 213us/step - loss: 0.9542 - accuracy: 0.7962 - val_loss: 0.4039 - val_accuracy: 0.7955\n",
            "Epoch 76/100\n",
            "5359/5359 [==============================] - 1s 231us/step - loss: 0.9281 - accuracy: 0.7962 - val_loss: 0.4037 - val_accuracy: 0.7955\n",
            "Epoch 77/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9935 - accuracy: 0.7962 - val_loss: 0.4033 - val_accuracy: 0.7955\n",
            "Epoch 78/100\n",
            "5359/5359 [==============================] - 1s 213us/step - loss: 0.8741 - accuracy: 0.7962 - val_loss: 0.4033 - val_accuracy: 0.7955\n",
            "Epoch 79/100\n",
            "5359/5359 [==============================] - 1s 228us/step - loss: 0.9910 - accuracy: 0.7962 - val_loss: 0.4078 - val_accuracy: 0.7955\n",
            "Epoch 80/100\n",
            "5359/5359 [==============================] - 1s 210us/step - loss: 0.9286 - accuracy: 0.7962 - val_loss: 0.4070 - val_accuracy: 0.7955\n",
            "Epoch 81/100\n",
            "5359/5359 [==============================] - 1s 202us/step - loss: 0.9295 - accuracy: 0.7962 - val_loss: 0.4076 - val_accuracy: 0.7955\n",
            "Epoch 82/100\n",
            "5359/5359 [==============================] - 1s 213us/step - loss: 0.8578 - accuracy: 0.7962 - val_loss: 0.4035 - val_accuracy: 0.7955\n",
            "Epoch 83/100\n",
            "5359/5359 [==============================] - 1s 211us/step - loss: 0.9596 - accuracy: 0.7962 - val_loss: 0.4253 - val_accuracy: 0.7955\n",
            "Epoch 84/100\n",
            "5359/5359 [==============================] - 1s 207us/step - loss: 0.8735 - accuracy: 0.7962 - val_loss: 0.4012 - val_accuracy: 0.7955\n",
            "Epoch 85/100\n",
            "5359/5359 [==============================] - 1s 207us/step - loss: 0.9511 - accuracy: 0.7962 - val_loss: 0.4062 - val_accuracy: 0.7955\n",
            "Epoch 86/100\n",
            "5359/5359 [==============================] - 1s 207us/step - loss: 0.8610 - accuracy: 0.7962 - val_loss: 0.4057 - val_accuracy: 0.7955\n",
            "Epoch 87/100\n",
            "5359/5359 [==============================] - 1s 209us/step - loss: 0.9134 - accuracy: 0.7962 - val_loss: 0.4089 - val_accuracy: 0.7955\n",
            "Epoch 88/100\n",
            "5359/5359 [==============================] - 1s 208us/step - loss: 0.9367 - accuracy: 0.7962 - val_loss: 0.4145 - val_accuracy: 0.7955\n",
            "Epoch 89/100\n",
            "5359/5359 [==============================] - 1s 200us/step - loss: 0.9449 - accuracy: 0.7962 - val_loss: 0.4021 - val_accuracy: 0.7955\n",
            "Epoch 90/100\n",
            "5359/5359 [==============================] - 1s 199us/step - loss: 0.8634 - accuracy: 0.7962 - val_loss: 0.4071 - val_accuracy: 0.7955\n",
            "Epoch 91/100\n",
            "5359/5359 [==============================] - 1s 238us/step - loss: 0.9122 - accuracy: 0.7962 - val_loss: 0.4051 - val_accuracy: 0.7955\n",
            "Epoch 92/100\n",
            "5359/5359 [==============================] - 1s 208us/step - loss: 0.9453 - accuracy: 0.7962 - val_loss: 0.4138 - val_accuracy: 0.7955\n",
            "Epoch 93/100\n",
            "5359/5359 [==============================] - 1s 201us/step - loss: 0.9665 - accuracy: 0.7962 - val_loss: 0.4069 - val_accuracy: 0.7955\n",
            "Epoch 94/100\n",
            "5359/5359 [==============================] - 1s 210us/step - loss: 0.9211 - accuracy: 0.7962 - val_loss: 0.4089 - val_accuracy: 0.7955\n",
            "Epoch 95/100\n",
            "5359/5359 [==============================] - 1s 202us/step - loss: 1.0214 - accuracy: 0.7962 - val_loss: 0.4073 - val_accuracy: 0.7955\n",
            "Epoch 96/100\n",
            "5359/5359 [==============================] - 1s 217us/step - loss: 0.8607 - accuracy: 0.7962 - val_loss: 0.4046 - val_accuracy: 0.7955\n",
            "Epoch 97/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9876 - accuracy: 0.7962 - val_loss: 0.4125 - val_accuracy: 0.7955\n",
            "Epoch 98/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 1.0090 - accuracy: 0.7962 - val_loss: 0.4059 - val_accuracy: 0.7955\n",
            "Epoch 99/100\n",
            "5359/5359 [==============================] - 1s 203us/step - loss: 0.9518 - accuracy: 0.7962 - val_loss: 0.4016 - val_accuracy: 0.7955\n",
            "Epoch 100/100\n",
            "5359/5359 [==============================] - 1s 201us/step - loss: 0.9506 - accuracy: 0.7962 - val_loss: 0.4028 - val_accuracy: 0.7955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSYDyfc5LPdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 3 - Making the predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFk6Bo-fLUhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiV2X6J4Lb1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "237d5ca1-c93d-436e-c9e9-2817f65000f3"
      },
      "source": [
        "cm"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1595,    0],\n",
              "       [ 405,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYZAWCr2LXvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JYFQypTLdxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "161440ab-f9ac-4885-c84d-1691296c9eb8"
      },
      "source": [
        "score"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ko8AlZKsbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "353f4bf4-7796-46f1-f9ce-77421a791fa8"
      },
      "source": [
        "# list all data in history\n",
        "\n",
        "print(model_history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN56_XoILLWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}
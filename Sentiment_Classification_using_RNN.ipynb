{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Classification_using_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOf/LDOFQFVageV7di4E36d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlie-aashutosh/Deep-Learning/blob/master/Sentiment_Classification_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQsoqjHV_WOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhYrULvV_Da8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-PLtOE6_D5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bb72cde-ebbe-45c6-c7d9-248ed2b2d30d"
      },
      "source": [
        "#setting vocabulary size and loading the test and train data\n",
        "vocabulary_size = 5000\n",
        "\n",
        "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=vocabulary_size)\n",
        "print('loaded dataset with {} training samples and {} test samples'.format(len(X_train),len(X_test)))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded dataset with 25000 training samples and 25000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PBwCWue_D-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "deba2546-7fef-4108-bc20-5b06f0e5737c"
      },
      "source": [
        "#getting a closer loook to our dataset\n",
        "print('---review---')\n",
        "print(X_train[10])\n",
        "print('---label---')\n",
        "print(y_train[10])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---review---\n",
            "[1, 785, 189, 438, 47, 110, 142, 7, 6, 2, 120, 4, 236, 378, 7, 153, 19, 87, 108, 141, 17, 1004, 5, 2, 883, 2, 23, 8, 4, 136, 2, 2, 4, 2, 43, 1076, 21, 1407, 419, 5, 2, 120, 91, 682, 189, 2818, 5, 9, 1348, 31, 7, 4, 118, 785, 189, 108, 126, 93, 2, 16, 540, 324, 23, 6, 364, 352, 21, 14, 9, 93, 56, 18, 11, 230, 53, 771, 74, 31, 34, 4, 2834, 7, 4, 22, 5, 14, 11, 471, 9, 2, 34, 4, 321, 487, 5, 116, 15, 2, 4, 22, 9, 6, 2286, 4, 114, 2679, 23, 107, 293, 1008, 1172, 5, 328, 1236, 4, 1375, 109, 9, 6, 132, 773, 2, 1412, 8, 1172, 18, 2, 29, 9, 276, 11, 6, 2768, 19, 289, 409, 4, 2, 2140, 2, 648, 1430, 2, 2, 5, 27, 3000, 1432, 2, 103, 6, 346, 137, 11, 4, 2768, 295, 36, 2, 725, 6, 3208, 273, 11, 4, 1513, 15, 1367, 35, 154, 2, 103, 2, 173, 7, 12, 36, 515, 3547, 94, 2547, 1722, 5, 3547, 36, 203, 30, 502, 8, 361, 12, 8, 989, 143, 4, 1172, 3404, 10, 10, 328, 1236, 9, 6, 55, 221, 2989, 5, 146, 165, 179, 770, 15, 50, 713, 53, 108, 448, 23, 12, 17, 225, 38, 76, 4397, 18, 183, 8, 81, 19, 12, 45, 1257, 8, 135, 15, 2, 166, 4, 118, 7, 45, 2, 17, 466, 45, 2, 4, 22, 115, 165, 764, 2, 5, 1030, 8, 2973, 73, 469, 167, 2127, 2, 1568, 6, 87, 841, 18, 4, 22, 4, 192, 15, 91, 7, 12, 304, 273, 1004, 4, 1375, 1172, 2768, 2, 15, 4, 22, 764, 55, 2, 5, 14, 4233, 2, 4, 1375, 326, 7, 4, 4760, 1786, 8, 361, 1236, 8, 989, 46, 7, 4, 2768, 45, 55, 776, 8, 79, 496, 98, 45, 400, 301, 15, 4, 1859, 9, 4, 155, 15, 66, 2, 84, 5, 14, 22, 1534, 15, 17, 4, 167, 2, 15, 75, 70, 115, 66, 30, 252, 7, 618, 51, 9, 2161, 4, 3130, 5, 14, 1525, 8, 2, 15, 2, 165, 127, 1921, 8, 30, 179, 2532, 4, 22, 9, 906, 18, 6, 176, 7, 1007, 1005, 4, 1375, 114, 4, 105, 26, 32, 55, 221, 11, 68, 205, 96, 5, 4, 192, 15, 4, 274, 410, 220, 304, 23, 94, 205, 109, 9, 55, 73, 224, 259, 3786, 15, 4, 22, 528, 1645, 34, 4, 130, 528, 30, 685, 345, 17, 4, 277, 199, 166, 281, 5, 1030, 8, 30, 179, 4442, 444, 2, 9, 6, 371, 87, 189, 22, 5, 31, 7, 4, 118, 7, 4, 2068, 545, 1178, 829]\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05UOSzm9EmTe",
        "colab_type": "text"
      },
      "source": [
        "#here we can see that revies is stored as a sequence of integers ~ word ID is pre assigned to individual words and label is 0 for negative and 1 for positive statment or review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr1gdzHcBSg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2644117f-b1ff-4d77-e00c-13660d7c92f3"
      },
      "source": [
        "word2id=imdb.get_word_index()\n",
        "id2word={i:word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i,'') for i in X_train[10]])\n",
        "print('---label---')\n",
        "print(y_train[10])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---review with words---\n",
            "['the', 'clear', 'fact', 'entertaining', 'there', 'life', 'back', 'br', 'is', 'and', 'show', 'of', 'performance', 'stars', 'br', 'actors', 'film', 'him', 'many', 'should', 'movie', 'reasons', 'to', 'and', 'reading', 'and', 'are', 'in', 'of', 'scenes', 'and', 'and', 'of', 'and', 'out', 'compared', 'not', 'boss', 'yes', 'to', 'and', 'show', 'its', 'disappointed', 'fact', 'raw', 'to', 'it', 'justice', 'by', 'br', 'of', 'where', 'clear', 'fact', 'many', 'your', 'way', 'and', 'with', 'city', 'nice', 'are', 'is', 'along', 'wrong', 'not', 'as', 'it', 'way', 'she', 'but', 'this', 'anything', 'up', \"haven't\", 'been', 'by', 'who', 'of', 'choices', 'br', 'of', 'you', 'to', 'as', 'this', \"i'd\", 'it', 'and', 'who', 'of', 'shot', \"you'll\", 'to', 'love', 'for', 'and', 'of', 'you', 'it', 'is', 'sequels', 'of', 'little', 'quest', 'are', 'seen', 'watched', 'front', 'chemistry', 'to', 'simply', 'alive', 'of', 'chris', 'being', 'it', 'is', 'say', 'easy', 'and', 'cry', 'in', 'chemistry', 'but', 'and', 'all', 'it', 'maybe', 'this', 'is', 'wing', 'film', 'job', 'live', 'of', 'and', 'relief', 'and', 'level', 'names', 'and', 'and', 'to', 'be', 'stops', 'serial', 'and', 'watch', 'is', 'men', 'go', 'this', 'of', 'wing', 'american', 'from', 'and', 'moving', 'is', 'accepted', 'put', 'this', 'of', 'jerry', 'for', 'places', 'so', 'work', 'and', 'watch', 'and', 'lot', 'br', 'that', 'from', 'sometimes', 'wondered', 'make', 'department', 'introduced', 'to', 'wondered', 'from', 'action', 'at', 'turns', 'in', 'low', 'that', 'in', 'gay', \"i'm\", 'of', 'chemistry', 'bible', 'i', 'i', 'simply', 'alive', 'it', 'is', 'time', 'done', 'inspector', 'to', 'watching', 'look', 'world', 'named', 'for', 'more', 'tells', 'up', 'many', 'fans', 'are', 'that', 'movie', 'music', 'her', 'get', 'grasp', 'but', 'seems', 'in', 'people', 'film', 'that', 'if', 'explain', 'in', 'why', 'for', 'and', 'find', 'of', 'where', 'br', 'if', 'and', 'movie', 'throughout', 'if', 'and', 'of', 'you', 'best', 'look', 'red', 'and', 'to', 'recently', 'in', 'successfully', 'much', 'unfortunately', 'going', 'dan', 'and', 'stuck', 'is', 'him', 'sequences', 'but', 'of', 'you', 'of', 'enough', 'for', 'its', 'br', 'that', 'beautiful', 'put', 'reasons', 'of', 'chris', 'chemistry', 'wing', 'and', 'for', 'of', 'you', 'red', 'time', 'and', 'to', 'as', 'companion', 'and', 'of', 'chris', 'less', 'br', 'of', 'subplots', 'torture', 'in', 'low', 'alive', 'in', 'gay', 'some', 'br', 'of', 'wing', 'if', 'time', 'actual', 'in', 'also', 'side', 'any', 'if', 'name', 'takes', 'for', 'of', 'friendship', 'it', 'of', '10', 'for', 'had', 'and', 'great', 'to', 'as', 'you', 'students', 'for', 'movie', 'of', 'going', 'and', 'for', 'bad', 'well', 'best', 'had', 'at', 'woman', 'br', 'musical', 'when', 'it', 'caused', 'of', 'gripping', 'to', 'as', 'gem', 'in', 'and', 'for', 'and', 'look', 'end', 'gene', 'in', 'at', 'world', 'aliens', 'of', 'you', 'it', 'meet', 'but', 'is', 'quite', 'br', 'western', 'ideas', 'of', 'chris', 'little', 'of', 'films', 'he', 'an', 'time', 'done', 'this', 'were', 'right', 'too', 'to', 'of', 'enough', 'for', 'of', 'ending', 'become', 'family', 'beautiful', 'are', 'make', 'right', 'being', 'it', 'time', 'much', 'bit', 'especially', 'craig', 'for', 'of', 'you', 'parts', 'bond', 'who', 'of', 'here', 'parts', 'at', 'due', 'given', 'movie', 'of', 'once', 'give', 'find', 'actor', 'to', 'recently', 'in', 'at', 'world', 'dolls', 'loved', 'and', 'it', 'is', 'video', 'him', 'fact', 'you', 'to', 'by', 'br', 'of', 'where', 'br', 'of', 'grown', 'fight', 'culture', 'leads']\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYd9v7uFB8cY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9e9dab3-1fa2-4978-d590-663e234ae579"
      },
      "source": [
        "#maximum and minimum review length\n",
        "print('maximum review length:{}'.format(len(max((X_train+X_test), key=len))))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maximum review length:2697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o27c8YM0CnNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab77c47a-8c21-40ae-9d3c-5d6b9a4aff13"
      },
      "source": [
        "print('minimum review length:{}'.format(len(min((X_train+X_test), key=len))))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minimum review length:70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA9ozCujEh44",
        "colab_type": "text"
      },
      "source": [
        "#padding the sequence ~ all input documents must have the same length while we feed them into the RNN, so we can limit the max review lenght to max_words by truncating longer reviews and padding shorter reviews with null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kYedMFQCvkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqafxcMsEx57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words=500\n",
        "X_train=sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test=sequence.pad_sequences(X_test,maxlen=max_words)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv0VyrxFFJBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#designing our RNN model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42vXhefGFTxQ",
        "colab_type": "text"
      },
      "source": [
        "Our input layer is sequence of words(integer word ID) of maximum length = max_words, output is a binary classifier label 0 or 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiVLJjQLFN95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "cf4e7c28-e4e4-494f-ebdf-ba2125590ec3"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39E1e6TbGgjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training and evaluation of our model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33tifw6pH3Hr",
        "colab_type": "text"
      },
      "source": [
        "We need to compile our model by specifying the loss function and optimizer we want to use while training as well as some evaluation metrices which we would like to measure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mBUVoijHyck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHrkPaGwIloG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#while training we need to specify the batch_size and the number of training epochs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWEwiqVzIpTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "405c7c4d-e9bd-4d32-d252-f9c2a21fc5d3"
      },
      "source": [
        "batch_size=64\n",
        "num_epochs=3\n",
        "\n",
        "X_valid,y_valid=X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "model.fit(X_train2,y_train2, validation_data=(X_valid,y_valid),batch_size=batch_size,epochs=num_epochs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "390/390 [==============================] - 230s 591ms/step - loss: 0.4896 - accuracy: 0.7534 - val_loss: 0.2884 - val_accuracy: 0.8594\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 233s 598ms/step - loss: 0.2949 - accuracy: 0.8819 - val_loss: 0.3354 - val_accuracy: 0.8438\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 238s 609ms/step - loss: 0.2465 - accuracy: 0.9034 - val_loss: 0.2127 - val_accuracy: 0.9219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd937cc2e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj0NTAPuJd8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "29d6e28d-2b46-4ba6-d966-1090f4b3caba"
      },
      "source": [
        "#let us see how well the model performs in case of test data\n",
        "scores=model.evaluate(X_test, y_test)\n",
        "print('Test_accuracy:',scores[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 73s 93ms/step - loss: 0.3077 - accuracy: 0.8758\n",
            "Test_accuracy: 0.8758000135421753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj4HQCAVMoKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}